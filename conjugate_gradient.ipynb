{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sexual-estimate",
   "metadata": {},
   "source": [
    "### Conjugate Gradient Method ###\n",
    "\n",
    "* solve $Qx = b$ for $x$\n",
    "* Medium ground between method of steepest descent (1st order, gradient) and Newton's method (2nd order, uses Hessian)\n",
    "\n",
    "#### Conditions ####\n",
    "\n",
    "* $Q$ is symmetric positive-definite\n",
    "\n",
    "#### Conjugation ####\n",
    "\n",
    "* The set of nonzero vectors $\\{d_1, d_2,..., d_k\\}$ are conjugate (also Q-orthogonal) with respect to $Q$ if\n",
    "\n",
    "$\\begin{equation}\n",
    "d_i^{T} Q d_j = 0 \\forall i \\ne j\n",
    "\\end{equation}$\n",
    "\n",
    "* If the set of vectors are Q-orthogonal, they are also linearly independent\n",
    "\n",
    "#### Optimization Problem ####\n",
    "\n",
    "Goal: $\\min_{x \\in \\mathbb{R}^n} \\frac{1}{2} x^T Q x - b^T x$\n",
    "\n",
    "the unique solution to this problem is also the unique solution to $Qx = b$\n",
    "\n",
    "Let $x^{*}$ denote the solution. Let $\\{d_0, d_2,..., d_{n-1}\\}$ be $Q$-conjugate. They are therefore a basis of the space, so\n",
    "\n",
    "$x^{*} = \\alpha_{0} d_{0} + ... + \\alpha_{n-1} d_{n-1}$\n",
    "\n",
    "and\n",
    "\n",
    "$d_{i}^T Q x^{*} = d_{i}^T Q(\\alpha_{0} d_{0} + ... + \\alpha_{n-1} d_{n-1}) = \\alpha_{i} d_{i}^TQd_{i}^T$\n",
    "\n",
    "and\n",
    "\n",
    "$\\alpha_{i} = \\dfrac{d_{i}^T Q x^{*}}{d_{i}^TQd_{i}^T}$, so\n",
    "\n",
    "$x^{*} = \\sum_{i=0}^{n-1} \\dfrac{d_{i}^T b}{d_{i}^TQd_{i}^T} d_i$\n",
    "\n",
    "Showing that we don't need to matrix invert $Q$ to solve for $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-melbourne",
   "metadata": {},
   "source": [
    "#### Conjugate Direction Theorem ####\n",
    "\n",
    "Let $\\{d_0, d_2,..., d_{n-1}\\}$ be $Q$-conjugate and $x_{0}$ an arbitrary starting point.\n",
    "\n",
    "The update rule is\n",
    "\n",
    "$x_{k+1} = x_{k} + \\alpha_{k} d_{k}$ where\n",
    "$g_{k} = Qx_{k} - b$ (gradient), and\n",
    "$a_{k} = - \\dfrac{g_{k}^T d_{k}}{d_{k}^T Q d_{k}} = - \\dfrac{(Qx_{k} - b)^T d_{k}}{d_{k}^T Q d_{k}}$\n",
    "\n",
    "After $n$ steps, $x_{n} = x^{*}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-matter",
   "metadata": {},
   "source": [
    "#### Conjugate Gradient Method ####\n",
    "\n",
    "We have the update rule $a_{k} = - \\dfrac{g_{k}^T d_{k}}{d_{k}^T Q d_{k}} = - \\dfrac{(Qx_{k} - b)^T d_{k}}{d_{k}^T Q d_{k}}$, but how should we choose the vectors $d_0,...,d_{n-1}$?\n",
    "\n",
    "They are chosen on-the-fly, at each step of the algorithm.\n",
    "\n",
    "Let $x_{i} \\in \\mathbb{R}^n$ be arbitrary.\n",
    "\n",
    "$d_{0} = -g_{0} = b - Q x_{0}$\n",
    "$\\alpha_{k} = - \\dfrac{g_{k}^T d_{k}}{d_{k}^T Q d_{k}}$\n",
    "$x_{k+1} = x_{k} + \\alpha_{k}d_{k}$\n",
    "$g_{k} = Qx_{k} - b$\n",
    "$d_{k+1} = - g_{k+1} + \\Beta_{k} d_{k}$\n",
    "$\\Beta_{k} = \\dfrac{g_{k+1}^T Q d_{k}}{d_{k}^T Q d_{k}}$\n",
    "\n",
    "What's $\\Beta_{}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-placement",
   "metadata": {},
   "source": [
    "#### Resources ####\n",
    "\n",
    "1. http://www.cs.cmu.edu/~aarti/Class/10725_Fall17/Lecture_Slides/conjugate_direction_methods.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-hawaii",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-pottery",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
